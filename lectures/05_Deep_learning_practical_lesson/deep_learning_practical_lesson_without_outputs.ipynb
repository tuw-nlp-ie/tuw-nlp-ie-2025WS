{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUJ9cPl-Fry3"
   },
   "source": [
    "# Natural Language Processing and Information Extraction\n",
    "## Deep learning - Practical Session\n",
    "\n",
    "__Nov 7, 2025__\n",
    "\n",
    "__Varvara Arzt__\n",
    "\n",
    "Material of this lecture was created by Ádám Kovács and extended by Varvara Arzt\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/tuw-nlp-ie/tuw-nlp-ie-2025WS/blob/main/lectures/05_Deep_learning_practical_lesson/deep_learning_practical_lesson_without_outputs.ipynb\" target=\"_parent\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-08G4DavFry5"
   },
   "source": [
    "## Dataset Overview:\n",
    "In this lecture, we are going to work with a classification dataset from [SemEval 2019 - Task 6](https://github.com/ZeyadZanaty/offenseval), which focuses on identifying and categorising Offensive Language in Social Media.\n",
    "\n",
    "## About SemEval:\n",
    "SemEval (Semantic Evaluation) is a series of international NLP research workshops where researchers compete to solve real-world language problems. Each year, organisers release datasets and challenges (called \"shared tasks\"), and teams from around the world build models to tackle these problems and compare their results. [Here](https://github.com/SemEval/SemEval2025/blob/main/tasks.md) you can find a list of shared tasks for SemEval-2025.\n",
    "\n",
    "## Tools and Setup\n",
    "\n",
    "### PyTorch\n",
    "\n",
    "We'll be using [PyTorch](https://pytorch.org/docs/stable/index.html), an open-source library for building deep learning models that can run efficiently on GPUs. It's one of the most widely used frameworks for neural networks in both research and industry.\n",
    "\n",
    "For your projects, you may want to explore **[HuggingFace](https://huggingface.co)** as well, a library that provides access to state-of-the-art pre-trained models and makes it much easier to work with modern transformer architectures.\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "**Dataset:**\n",
    "- SemEval 2019 - Task 6 dataset (code for downloading will be provided)\n",
    "\n",
    "**Required Libraries:**\n",
    "\n",
    "- PyTorch, pandas, scikit-learn, spacy\n",
    "- transformers, accelerate, safetensors (for HuggingFace models)\n",
    "- wandb (for experiment tracking)\n",
    "\n",
    "### Installation\n",
    "\n",
    "Run the following commands to install all required packages:\n",
    "```python\n",
    "# Install required packages\n",
    "!pip install -q torch pandas scikit-learn spacy transformers accelerate safetensors wandb emoji==0.6.0\n",
    "\n",
    "# Download spacy language model\n",
    "!python -m spacy download en_core_web_sm\n",
    "```\n",
    "\n",
    "For OS-specific or CUDA-enabled PyTorch installation, consult the [PyTorch installation guide](https://pytorch.org/get-started/locally/).\n",
    "\n",
    "> **Note:** We strongly recommend using [Google Colab](https://colab.research.google.com/) for this lab. It provides free GPU access and ensures a consistent environment for everyone, making it easier to reproduce results.\n",
    "\n",
    "## What We'll Cover\n",
    "\n",
    "In this lecture, we'll explore different approaches for text classification, progressing from simple to more advanced models:\n",
    "\n",
    "1. **Feed Forward Neural Network (FNN)** with Bag-of-Words representation\n",
    "2. **Multi-layer FNNs** for deeper feature learning\n",
    "3. **Neural Networks with embedding layers** (+ max-pooling)\n",
    "4. **Recurrent Neural Networks (RNNs)** and **LSTM networks** for sequential processing\n",
    "5. **Transformer architecture (BERT)** for state-of-the-art performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eZt9zm2LFry6",
    "outputId": "c2bdc279-bcad-45a5-fa44-d5c09b976c66"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch pandas scikit-learn spacy transformers accelerate safetensors wandb\n",
    "!pip3 install emoji==0.6.0\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4Xkf04_Fry7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import urllib.request\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    AutoTokenizer, \n",
    "    BertForSequenceClassification,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "import wandb\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDFv7TnVFry8"
   },
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0gNCsikFry8",
    "outputId": "7f7c0a4a-559a-42dd-ded7-6e1d1cd517ee"
   },
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "dataset_url = \"https://raw.githubusercontent.com/ZeyadZanaty/offenseval/master/datasets/training-v1/offenseval-training-v1.tsv\"\n",
    "dataset_path = \"data/offenseval.tsv\"\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    urllib.request.urlretrieve(dataset_url, dataset_path)\n",
    "    print(\"Dataset downloaded successfully\")\n",
    "else:\n",
    "    print(\"Dataset already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xxkoCVUFry8"
   },
   "source": [
    "### Read in the dataset into a Pandas DataFrame\n",
    "Load the dataset into a Pandas DataFrame using `pd.read_csv()`. The dataset is tab-separated and contains 5 columns:\n",
    "`id`, `tweet`, `subtask_a`, `subtask_b`, `subtask_c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14AzL6GHFry9",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eef320fdacfdf485",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    train_data = pd.read_csv(\"./data/offenseval.tsv\", sep=\"\\t\")\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "rNCxGm0LFry-",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8f39b3b86623648c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "c38ebe19-f5ba-42bb-a7c0-a8f0028def60"
   },
   "outputs": [],
   "source": [
    "train_data_unprocessed = read_dataset()\n",
    "train_data_unprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8sKz1zsFry-"
   },
   "source": [
    "### Convert `subtask_a` Labels to Binary Format\n",
    "The task is to classify tweets as either offensive (OFF) or not offensive (NOT). For machine learning algorithms, you will need integer labels instead of strings. Create a new column called `label` where:\n",
    "- `NOT` → 0 (not offensive)\n",
    "- `OFF` → 1 (offensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQ4VazgwFry-",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-595b437c85da4194",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def transform(train_data):\n",
    "    labels = {\"NOT\": 0, \"OFF\": 1}\n",
    "\n",
    "    train_data[\"label\"] = [labels[item] for item in train_data.subtask_a]\n",
    "    train_data[\"tweet\"] = train_data[\"tweet\"].str.replace(\"@USER\", \"\")\n",
    "\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zSHYynQ3Fry_",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-56fa86b834804581",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_data = transform(train_data_unprocessed)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNUUEApz3d_d",
    "outputId": "5e36ca26-0c39-4db8-8895-cd83effbe489"
   },
   "outputs": [],
   "source": [
    "train_data.groupby(\"subtask_a\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypaOR-1EFrzA"
   },
   "source": [
    "### Split the dataset into a train and a validation dataset\n",
    "Use the random seed for splitting. You should split the dataset into 70% training data and 30% validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSeRGX4KFrzB",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-20ba609174c640e7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def split_data(train_data, random_seed):\n",
    "    tr_data, val_data = train_test_split(train_data, test_size=0.3, random_state=SEED)\n",
    "    return tr_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bK6m0rRFrzB",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0e8a125310d3fea9",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tr_data, val_data = split_data(train_data, SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHxBtAYNFrzB"
   },
   "source": [
    "## 3. Text Preprocessing with CountVectorizer\n",
    "\n",
    "We'll use [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) from scikit-learn to convert text into numerical features. This tool will:\n",
    "\n",
    "- Tokenize, lowercase the text\n",
    "- Filter out stopwords\n",
    "- Convert the text into one-hot encoded vectors\n",
    "- Select the _n_-best features\n",
    "\n",
    "We fit CountVectorizer using _3000_ features (vocabulary size)\n",
    "\n",
    "We will also _lemmatize_ texts using the _spaCy_ package and its lemmatizer. Check the [docs](https://spacy.io/models/en) for more.\n",
    "\n",
    "CountVectorizer transforms text into a Bag-of-Words representation by counting how many times each word appears in a document. This creates a document-term matrix where each row is a document and each column is a word from the vocabulary.\n",
    "\n",
    "![Bag-of-Words visualization](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*3IACMnNpwVlCl8kSTJocPA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "shzT5AX0FrzC",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c0943811065a971f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "c8f11496-f926-4f27-d848-43b91cea471d"
   },
   "outputs": [],
   "source": [
    "# Load spaCy model (disable unused components for speed)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "class SpacyLemmaTokenizer:\n",
    "    \"\"\"Custom tokenizer that lemmatizes words using spaCy.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.nlp = nlp\n",
    "    \n",
    "    def __call__(self, doc):\n",
    "        return [token.lemma_ for token in self.nlp(doc)]\n",
    "\n",
    "\n",
    "def prepare_vectorizer(tr_data):\n",
    "    \"\"\"Initialize and fit CountVectorizer on training data.\"\"\"\n",
    "    vectorizer = CountVectorizer(\n",
    "        max_features=3000,\n",
    "        tokenizer=SpacyLemmaTokenizer(),\n",
    "        stop_words=\"english\"\n",
    "    )\n",
    "\n",
    "    word_to_ix = vectorizer.fit(tr_data.tweet)\n",
    "\n",
    "    return word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xq4NYTdcFrzC",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a2c6658aef3041dc",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Fit vectorizer on training data\n",
    "word_to_ix = prepare_vectorizer(tr_data)\n",
    "VOCAB_SIZE = len(word_to_ix.vocabulary_)\n",
    "assert VOCAB_SIZE == 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Lemmatization with spaCy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "sentence = \"the kids are running happily towards the cars\"\n",
    "doc = nlp(sentence)\n",
    "\n",
    "print(\"Original:\", [token.text for token in doc])\n",
    "print(\"Lemmatized:\", [token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View top 10 most frequent words in our dataset after preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training data to Bag-of-Words representation\n",
    "X = word_to_ix.transform(tr_data.tweet)\n",
    "\n",
    "# Top 10 words\n",
    "top_10 = sorted([(word, X.sum(axis=0).A1[idx]) for word, idx in word_to_ix.vocabulary_.items()], \n",
    "                key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "print(\"Top 10 words:\", top_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Transform a new sentence to a Bag-of-Words representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rlxFUWI3d_g",
    "outputId": "abe8cc9c-1898-4930-8a9b-e104b314dab2"
   },
   "outputs": [],
   "source": [
    "example = word_to_ix.transform([\"he loves science\"]).toarray()\n",
    "print(f\"Bag-of-words vector: '{example}':\")\n",
    "print(f\"Vector shape: {example.shape}\")\n",
    "print(f\"Non-zero positions: {example.nonzero()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrlPM_d1FrzC"
   },
   "source": [
    "## 4. Prepare the DataLoader for Batch Processing\n",
    "\n",
    "The `prepare_dataloader()` function converts our text data into PyTorch tensors:\n",
    "\n",
    "1. **Transform tweets** into one-hot encoded vectors using CountVectorizer\n",
    "2. **Create tensors** from the vectors and labels (FloatTensor for features, LongTensor for labels)\n",
    "3. **Move tensors to device** (GPU/CPU) - all tensors must be on the same device for training\n",
    "4. **Zip together** features and labels as a list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-6VMlD-FrzD",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-67b120b4ea6ba288",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# PyTorch operates on Tensors - optimized data structures for training neural networks\n",
    "# Learn more: https://pytorch.org/docs/stable/tensors.html\n",
    "def prepare_dataloader(tr_data, val_data, word_to_ix):\n",
    "    \"\"\"\n",
    "    Convert text data to PyTorch tensors.\n",
    "    \n",
    "    Args:\n",
    "        tr_data: Training dataset\n",
    "        val_data: Validation dataset\n",
    "        word_to_ix: Fitted CountVectorizer\n",
    "    \n",
    "    Returns:\n",
    "        tr_data_loader: List of (features, label) tuples for training\n",
    "        val_data_loader: List of (features, label) tuples for validation\n",
    "    \"\"\"\n",
    "    # Transform text to one-hot encoded vectors and convert to tensors\n",
    "    tr_data_vecs = torch.FloatTensor(word_to_ix.transform(tr_data.tweet).toarray()).to(\n",
    "        device\n",
    "    )\n",
    "    tr_labels = torch.LongTensor(tr_data.label.tolist()).to(device)\n",
    "\n",
    "    val_data_vecs = torch.FloatTensor(\n",
    "        word_to_ix.transform(val_data.tweet).toarray()\n",
    "    ).to(device)\n",
    "    val_labels = torch.LongTensor(val_data.label.tolist()).to(device)\n",
    "\n",
    "    # Create list of (sample, label) tuples\n",
    "    tr_data_loader = [(sample, label) for sample, label in zip(tr_data_vecs, tr_labels)]\n",
    "    val_data_loader = [\n",
    "        (sample, label) for sample, label in zip(val_data_vecs, val_labels)\n",
    "    ]\n",
    "\n",
    "    return tr_data_loader, val_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQG5rdlpFrzD",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-212fb18e207761c4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tr_data_loader, val_data_loader = prepare_dataloader(tr_data, val_data, word_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Our current approach loads and transforms the entire dataset into memory at once. This works perfectly for smaller datasets like OffensEval (~13,000 tweets). For larger datasets that don't fit in memory (e.g., millions of images or documents), you would use PyTorch's custom `torch.utils.data.Dataset` class, which loads and processes data on-the-fly as each batch is needed during training. See the [documentation](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) for examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxHwnckHFrzD"
   },
   "source": [
    "### Create DataLoader Objects for Batch Processing\n",
    "\n",
    "Now we'll wrap our data in PyTorch's `DataLoader` class, which handles batching and shuffling automatically.\n",
    "\n",
    "**Why batching?** We don't feed the entire dataset to the model at once. Instead, we process small batches (e.g., 64 samples) at a time, which:\n",
    "- Reduces memory usage\n",
    "- Provides more frequent weight updates\n",
    "- Often leads to better model generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1DPygZyFrzE"
   },
   "outputs": [],
   "source": [
    "# Batch size: number of samples processed before updating model weights\n",
    "# Try experimenting with different values (8, 16, 32, 64, 128) to see the impact on performance\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BT3hbbGjFrzD",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-96ac025a45bc4fec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def create_dataloader_iterators(tr_data_loader, val_data_loader, BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Create DataLoader objects for batched training.\n",
    "    \n",
    "    Args:\n",
    "        tr_data_loader: List of training (features, label) tuples\n",
    "        val_data_loader: List of validation (features, label) tuples\n",
    "        batch_size: Number of samples per batch\n",
    "    \n",
    "    Returns:\n",
    "        train_iterator: DataLoader for training (shuffled)\n",
    "        valid_iterator: DataLoader for validation (not shuffled)\n",
    "    \"\"\"\n",
    "    # Shuffle training data each epoch to prevent the model from learning order patterns\n",
    "    # Don't shuffle validation data - we want consistent evaluation\n",
    "    \n",
    "    train_iterator = DataLoader(\n",
    "        tr_data_loader,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    valid_iterator = DataLoader(\n",
    "        val_data_loader,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return train_iterator, valid_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zvvqcuk3FrzE",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7b88321ec3ee1096",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator = create_dataloader_iterators(\n",
    "    tr_data_loader, val_data_loader, BATCH_SIZE\n",
    ")\n",
    "assert type(train_iterator) == torch.utils.data.dataloader.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uke6iYPh3d_i",
    "outputId": "970899de-7eba-4f52-c0b7-24d3ae533df7"
   },
   "outputs": [],
   "source": [
    "print(f\"Number of training batches: {len(train_iterator)}\")\n",
    "print(f\"Number of validation batches: {len(valid_iterator)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WUTDwv2FrzE"
   },
   "source": [
    "## 5. Building the Model\n",
    "\n",
    "### Simple Bag-of-Words Classifier\n",
    "\n",
    "Our first model is a simple single-layer neural network:\n",
    "- **Input:** Bag-of-Words vectors (size = vocabulary size)\n",
    "- **Output:** Class probabilities (2 classes: offensive/not offensive)\n",
    "- **Architecture:** One linear transformation followed by softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HqwUwPUdFrzF",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-00fb572132edf99a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class BoWClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple Bag-of-Words classifier with one linear layer.\n",
    "    \n",
    "    Note: All PyTorch models must inherit from nn.Module.\n",
    "    This is a 'shallow' network with just one layer - we'll build deeper ones later!\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, num_labels):\n",
    "        # Always call the parent class constructor in PyTorch models\n",
    "        # This initializes important internal mechanisms\n",
    "        super(BoWClassifier, self).__init__()\n",
    "\n",
    "        # Single linear layer: applies transformation y = xW^T + b\n",
    "        # To make this \"deep\", add more nn.Linear layers with activation functions\n",
    "        # (e.g., ReLU) between them. For now, this shallow architecture serves as our baseline.\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "\n",
    "    def forward(self, bow_vec, sequence_lens=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            bow_vec: Bag-of-Words input vectors [batch_size, vocab_size]\n",
    "            sequence_lens: Not used in this model, but included for compatibility \n",
    "                          with later models (RNN/LSTM) that need sequence lengths\n",
    "        \n",
    "        Returns:\n",
    "            Log probabilities for each class [batch_size, num_labels]\n",
    "        \"\"\"\n",
    "        # Pass input through the linear layer\n",
    "        output = self.linear(bow_vec)\n",
    "        # Apply log_softmax to convert raw scores into log probabilities\n",
    "        # Softmax creates a probability distribution (values sum to 1)\n",
    "        # log_softmax is more stable than softmax and works with NLLLoss\n",
    "        # dim=1 means we apply softmax across the class dimension, not the batch dim\n",
    "        return nn.functional.log_softmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lr-4sjO3FrzF",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3cbec9b993598632",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = VOCAB_SIZE # Size of our vocabulary\n",
    "OUTPUT_DIM = 2 # Binary classification: offensive vs not offensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vVxRlyR-FrzF",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-203697b21306ccb9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = BoWClassifier(INPUT_DIM, OUTPUT_DIM)\n",
    "print(model)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())} weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore the model weights:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model starts with random weights\n",
    "print(f\"Weight matrix shape: {model.linear.weight.shape}\")\n",
    "print(f\"First few weights:\\n{model.linear.weight[:2, :5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEIXHRUTFrzF"
   },
   "outputs": [],
   "source": [
    "# Optimizer: updates model weights based on gradients\n",
    "# Adam is a popular choice that adapts the learning rate automatically\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# Loss function: Negative Log Likelihood Loss (works with log_softmax output)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K0pDsTdKFrzG",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9852177c09074615",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Move model and loss function to the correct device (GPU/CPU)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BSC-ttlFrzG",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-50c925cbe0576fd3",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert model.linear.out_features == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation Functions\n",
    "\n",
    "### Performance Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCrTcch_FrzG"
   },
   "source": [
    "### Training and evaluating PyTorch models\n",
    "- __calculate_performance__: This should calculate the batch-wise precision, recall, and fscore of your model!\n",
    "- __train__ - Train your model on the training data! This function should set the model to training mode, then use the given iterator to iterate through the training samples and make predictions using the provided model. You should then propagate back the error with the loss function and the optimizer. Finally return the average epoch loss and performance!\n",
    "- __evaluate__ - Evaluate your model on the validation dataset. This function is essentially the same as the trainnig function, but you should set your model to eval mode and don't propagate back the errors to your weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9TWQekCdFrzG",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1818f7b4bce37196",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def calculate_performance(preds, y):\n",
    "    \"\"\"\n",
    "    Calculate precision, recall, and F-score for predictions.\n",
    "    \n",
    "    Args:\n",
    "        preds: Model predictions (log probabilities)\n",
    "        y: True labels\n",
    "    \n",
    "    Returns:\n",
    "        precision, recall, fscore for the positive class (offensive)\n",
    "    \"\"\"\n",
    "    # Get predicted class (highest probability)\n",
    "    rounded_preds = preds.argmax(1)\n",
    "\n",
    "    # Calculate the correct predictions batch-wise and calculate precision, recall, and fscore\n",
    "    # WARNING: Tensors here could be on the GPU, so make sure to copy everything to CPU\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(\n",
    "        rounded_preds.cpu(), y.cpu()\n",
    "    )\n",
    "\n",
    "    return precision[1], recall[1], fscore[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhzACM5IFrzG",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ea8beb3df906f9a4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network model\n",
    "        iterator: DataLoader for training data\n",
    "        optimizer: Optimizer for updating weights\n",
    "        criterion: Loss function\n",
    "    \n",
    "    Returns:\n",
    "        Average loss, precision, recall, and F-score for the epoch\n",
    "    \"\"\"\n",
    "    epoch_loss = 0\n",
    "    epoch_prec = 0\n",
    "    epoch_recall = 0\n",
    "    epoch_fscore = 0\n",
    "\n",
    "    # Set model to training mode (enables gradient computation)\n",
    "    model.train()\n",
    "\n",
    "    # We calculate the error on batches so the iterator will return matrices with shape [BATCH_SIZE, VOCAB_SIZE]\n",
    "    for batch in iterator:\n",
    "        text_vecs = batch[0] # Input features\n",
    "        labels = batch[1]   # True labels\n",
    "        sen_lens = []\n",
    "        texts = []\n",
    "\n",
    "        # Handle additional batch elements for later models\n",
    "        if len(batch) > 2:\n",
    "            sen_lens = batch[2]\n",
    "            texts = batch[3]\n",
    "\n",
    "        # Reset gradients from previous step\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: compute predictions\n",
    "        predictions = model(text_vecs, sen_lens)\n",
    "\n",
    "        # Calculate loss on  predictions (predictions are log probabilities)\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        # Calculate performance metrics\n",
    "        prec, recall, fscore = calculate_performance(predictions, labels)\n",
    "\n",
    "        # Backward pass: compute gradients\n",
    "        loss.backward()\n",
    "        # Update model weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Add batch-wise loss to the epoch-wise loss\n",
    "        epoch_loss += loss.item()\n",
    "        # Do the same with the performance metrics\n",
    "        epoch_prec += prec.item()\n",
    "        epoch_recall += recall.item()\n",
    "        epoch_fscore += fscore.item()\n",
    "    # Return average metrics over all batches\n",
    "    return (\n",
    "        epoch_loss / len(iterator),\n",
    "        epoch_prec / len(iterator),\n",
    "        epoch_recall / len(iterator),\n",
    "        epoch_fscore / len(iterator),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASFglaVtFrzH",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-810fadb1db8e2028",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# The evaluation is done on the validation dataset\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \"\"\"\n",
    "    Evaluate the model on validation data.\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network model\n",
    "        iterator: DataLoader for validation data\n",
    "        criterion: Loss function\n",
    "    \n",
    "    Returns:\n",
    "        Average loss, precision, recall, and F-score for the validation set\n",
    "    \"\"\"\n",
    "    epoch_loss = 0\n",
    "    epoch_prec = 0\n",
    "    epoch_recall = 0\n",
    "    epoch_fscore = 0\n",
    "    # Set model to evaluation mode (disables dropout, batchnorm updates, etc.)\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation (saves memory and speeds up evaluation)\n",
    "    with torch.no_grad():\n",
    "        # The remaining part is the same with the difference of not using the optimizer to backpropagation\n",
    "        for batch in iterator:\n",
    "            text_vecs = batch[0]\n",
    "            labels = batch[1]\n",
    "            sen_lens = []\n",
    "            texts = []\n",
    "\n",
    "            if len(batch) > 2:\n",
    "                sen_lens = batch[2]\n",
    "                texts = batch[3]\n",
    "\n",
    "            # Forward pass only (no backward pass)\n",
    "            predictions = model(text_vecs, sen_lens)\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            prec, recall, fscore = calculate_performance(predictions, labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_prec += prec.item()\n",
    "            epoch_recall += recall.item()\n",
    "            epoch_fscore += fscore.item()\n",
    "\n",
    "    # Return average metrics on the whole epoch\n",
    "    return (\n",
    "        epoch_loss / len(iterator),\n",
    "        epoch_prec / len(iterator),\n",
    "        epoch_recall / len(iterator),\n",
    "        epoch_fscore / len(iterator),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzRshE3-FrzH",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-73c8635f8fc4a7fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    \"\"\"Calculate and format training time.\"\"\"\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, valid_losses, n_epochs):\n",
    "    \"\"\"Plot training and validation losses over epochs.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, n_epochs + 1), train_losses, label=\"Training Loss\")\n",
    "    plt.plot(range(1, n_epochs + 1), valid_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss Over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBcx1vxBFrzH"
   },
   "source": [
    "Now let's train the model! The training loop will:\n",
    "1. Train on the training set for each epoch\n",
    "2. Evaluate on the validation set\n",
    "3. Save the best model (lowest validation loss)\n",
    "4. Plot the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGaJR3xTFrzH"
   },
   "outputs": [],
   "source": [
    "def training_loop(epoch_number=15):\n",
    "    \"\"\"\n",
    "    Main training loop.\n",
    "    \n",
    "    Args:\n",
    "        epoch_number: Number of epochs to train\n",
    "    \"\"\"\n",
    "    N_EPOCHS = epoch_number\n",
    "\n",
    "    best_valid_loss = float(\"inf\")\n",
    "\n",
    "    # Lists to store loss values for plotting\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    # We loop forward on the epoch number\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train the model on the training set using the dataloader for one epoch\n",
    "        train_loss, train_prec, train_rec, train_fscore = train(\n",
    "            model, train_iterator, optimizer, criterion\n",
    "        )\n",
    "        # Evaluate on validation set\n",
    "        valid_loss, valid_prec, valid_rec, valid_fscore = evaluate(\n",
    "            model, valid_iterator, criterion\n",
    "        )\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        # Store losses\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        # Save best model\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), \"tut1-model.pt\")\n",
    "            \n",
    "        # Print progress\n",
    "        print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "        print(\n",
    "            f\"\\tTrain Loss: {train_loss:.3f} | Train Prec: {train_prec*100:.2f}% | Train Rec: {train_rec*100:.2f}% | Train Fscore: {train_fscore*100:.2f}%\"\n",
    "        )\n",
    "        print(\n",
    "            f\"\\t Val. Loss: {valid_loss:.3f} |  Val Prec: {valid_prec*100:.2f}% | Val Rec: {valid_rec*100:.2f}% | Val Fscore: {valid_fscore*100:.2f}%\"\n",
    "        )\n",
    "    plot_losses(train_losses, valid_losses, N_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZIm70jWgQq21",
    "outputId": "caeb182a-667f-49be-afa7-78ba6fe6027d"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# Try different epoch numbers to find the sweet spot between underfitting and overfitting\n",
    "training_loop(epoch_number=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important: Model Reinitialization\n",
    "\n",
    "> **Critical:** If you want to train the model from scratch multiple times, you **must** reinitialize it. Otherwise, training will continue from where it left off rather than starting fresh with random weights.\n",
    "\n",
    "To reinitialize the model, rerun these lines:\n",
    "```python\n",
    "# Reinitialize model with random weights\n",
    "model = BoWClassifier(INPUT_DIM, OUTPUT_DIM)\n",
    "\n",
    "# Reinitialize optimizer (needs to track the new model's parameters)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Reinitialize loss function\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Move to device\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or create a helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOpuzSyfPwBh"
   },
   "outputs": [],
   "source": [
    "def reinitialize(model):\n",
    "    \"\"\"Reinitialize model, optimizer, and loss function.\"\"\"\n",
    "    # Create new model instance\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.NLLLoss()\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgflJA47P3O-"
   },
   "outputs": [],
   "source": [
    "reinitialize(BoWClassifier(INPUT_DIM, OUTPUT_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFcqasArFrzI"
   },
   "source": [
    "## 6. Building a Deeper Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSv9C_heFrzJ"
   },
   "source": [
    "### Adding Hidden Layers\n",
    "\n",
    "Our current model has only one layer. Let's make it \"deep\" by adding:\n",
    "- **Hidden layer:** An intermediate representation between input and output\n",
    "- **ReLU activation:** A non-linear function that allows the network to learn complex patterns\n",
    "- **Multiple transformations:** Input → Hidden → Output\n",
    "\n",
    "**Why add depth?**\n",
    "- Single layers can only learn linear relationships\n",
    "- Hidden layers with activations enable learning non-linear patterns\n",
    "- This often improves performance on complex tasks\n",
    "\n",
    "\n",
    "\n",
    "Learn more:\n",
    "- [ReLU activation](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_S4Ytz8HFrzJ",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f71eea2d6e70ad97",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class BoWDeepClassifier(nn.Module):\n",
    "    def __init__(self, num_labels, vocab_size, hidden_size):\n",
    "        \"\"\"Deep Bag-of-Words classifier with one hidden layer.\"\"\"\n",
    "\n",
    "        super(BoWDeepClassifier, self).__init__()\n",
    "        # First layer: transform from vocabulary size to hidden size\n",
    "        self.linear1 = nn.Linear(vocab_size, hidden_size)\n",
    "        #Non-linear activation function\n",
    "        # ReLU(x) = max(0, x) - introduces non-linearity between layers\n",
    "        # Without this, multiple linear layers would collapse into a single linear transformation\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        # Second layer: transform from hidden size to number of classes\n",
    "        self.linear2 = nn.Linear(hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, bow_vec, sequence_lens=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            bow_vec: Input Bag-of-Words vectors\n",
    "            sequence_lens: Not used (kept for compatibility)\n",
    "        \n",
    "        Returns:\n",
    "            Log probabilities for each class\n",
    "        \"\"\"\n",
    "        output = self.linear1(bow_vec)\n",
    "        output = self.relu(output)\n",
    "        output = self.linear2(output)\n",
    "\n",
    "        # Get the log probabilities\n",
    "        return nn.functional.log_softmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5tw97UGFrzK"
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 200 # Size of the hidden layer - try experimenting with this!\n",
    "learning_rate = 0.001\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7flTZ3vgFrzK"
   },
   "outputs": [],
   "source": [
    "model = BoWDeepClassifier(OUTPUT_DIM, INPUT_DIM, HIDDEN_SIZE) # initialize the model\n",
    "\n",
    "# Set up optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Move to device\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# Display model architecture\n",
    "print(model)\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Experiment:** Try different values for `HIDDEN_SIZE` (e.g., 50, 100, 200, 500) and see how it affects performance. Larger hidden sizes can learn more complex patterns but may overfit on small datasets.Retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNZV21ShFrzK",
    "outputId": "9fac20f9-bbb4-4ad4-97bd-3f8c52bee3b8"
   },
   "outputs": [],
   "source": [
    "training_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRInQ1ToFrzK"
   },
   "source": [
    "## 7. Early Stopping to Prevent Overfitting\n",
    "\n",
    "### What is Early Stopping?\n",
    "\n",
    "Early stopping is a simple but effective technique to prevent overfitting. The idea:\n",
    "- Monitor validation loss during training\n",
    "- If validation loss stops improving for several consecutive epochs (while training loss may still decrease), stop training\n",
    "- This prevents the model from memorizing the training data\n",
    "\n",
    "**Why it works:** When validation loss stops improving but training loss keeps decreasing, the model is likely starting to overfit to the training data rather than learning generalizable patterns.\n",
    "\n",
    "### Implementation\n",
    "\n",
    "We'll implement a patience-based early stopping:\n",
    "- **Patience:** Number of epochs to wait for improvement before stopping\n",
    "- If validation loss doesn't improve for `patience` consecutive epochs, training stops automatically\n",
    "- We save the best model (lowest validation loss) during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IyxNctC13d_m"
   },
   "outputs": [],
   "source": [
    "# Reinitialize model for fresh training\n",
    "model = BoWDeepClassifier(OUTPUT_DIM, INPUT_DIM, HIDDEN_SIZE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Bl4-i-c3d_m"
   },
   "outputs": [],
   "source": [
    "def training_loop(epoch_number=15, patience=3):\n",
    "    \"\"\"\n",
    "    Training loop with early stopping.\n",
    "    \n",
    "    Args:\n",
    "        epoch_number: Maximum number of epochs to train\n",
    "        patience: Number of epochs to wait for improvement before stopping\n",
    "    \n",
    "    Returns:\n",
    "        best_valid_loss: Best validation loss achieved during training\n",
    "    \"\"\"\n",
    "    N_EPOCHS = epoch_number\n",
    "    consecutive_no_improvement = 0\n",
    "\n",
    "    best_valid_loss = float(\"inf\")  # Initialize with infinity (any loss will be better)\n",
    "\n",
    "    # Store losses for plotting\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    # We loop forward on the epoch number\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train and evaluate\n",
    "        train_loss, train_prec, train_rec, train_fscore = train(\n",
    "            model, train_iterator, optimizer, criterion\n",
    "        )\n",
    "        \n",
    "        valid_loss, valid_prec, valid_rec, valid_fscore = evaluate(\n",
    "            model, valid_iterator, criterion\n",
    "        )\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        # Store losses\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        # Check if validation loss improved\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            consecutive_no_improvement = 0 # Reset counter\n",
    "            torch.save(model.state_dict(), \"bow-deep-model.pt\")\n",
    "\n",
    "        else:\n",
    "            consecutive_no_improvement += 1 # Increment counter\n",
    "\n",
    "        # Print epoch results\n",
    "        print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "        print(\n",
    "            f\"\\tTrain Loss: {train_loss:.3f} | Train Prec: {train_prec*100:.2f}% | Train Rec: {train_rec*100:.2f}% | Train Fscore: {train_fscore*100:.2f}%\"\n",
    "        )\n",
    "        print(\n",
    "            f\"\\t Val. Loss: {valid_loss:.3f} |  Val Prec: {valid_prec*100:.2f}% | Val Rec: {valid_rec*100:.2f}% | Val Fscore: {valid_fscore*100:.2f}%\"\n",
    "        )\n",
    "\n",
    "        # Early stopping check\n",
    "        if consecutive_no_improvement >= patience:\n",
    "            print(f\"No improvement in validation loss for {patience} consecutive epochs. Early stopping after epoch {epoch+1}.\")\n",
    "            break  # Terminate training loop\n",
    "\n",
    "    plot_losses(train_losses, valid_losses, n_epochs=epoch+1)\n",
    "        \n",
    "    return best_valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DH9SEm3c3d_m",
    "outputId": "551a0d27-c3f2-45c9-f970-fc96b60cb428"
   },
   "outputs": [],
   "source": [
    "training_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAN4Y5s3FrzL"
   },
   "source": [
    "## 8. Handling class imbalance\n",
    "\n",
    "Our data is imbalanced. The NOT class (0) has roughly twice as many samples as the OFF class (1). This imbalance can bias the model toward predicting the majority class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S9_wXYqlFrzL",
    "outputId": "4617dc32-3f17-49d0-b8ae-5320e01022d8"
   },
   "outputs": [],
   "source": [
    "tr_data.groupby(\"label\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Weighted Loss Function\n",
    "\n",
    "We can penalize errors on the minority class more heavily by adding weights to our loss function. The idea is to weight each class by the inverse of its frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5FoqDTQIFrzL",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6ebf131781a3332d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Class 1 (offensive) appears half as often, so weight it twice as much\n",
    "weights = torch.Tensor([1, 2])\n",
    "criterion = nn.NLLLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BoWDeepClassifier(OUTPUT_DIM, INPUT_DIM, HIDDEN_SIZE)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss(weight=weights)\n",
    "\n",
    "# Train\n",
    "training_loop(epoch_number=15, patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBu230DWRYwK"
   },
   "source": [
    "## 9. Adding Embedding Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9F_lJrzr3d_m"
   },
   "source": [
    "### Why Move Beyond Bag-of-Words?\n",
    "- So far, we've only used Bag-of-Words representations (size 3000) as features. Limitations:\n",
    "- **Sparse:** Most values are zero\n",
    "- **No word relationships:** \"good\" and \"great\" are treated as completely different\n",
    "- **Large dimensionality:** 3000 features for 3000 vocabulary words\n",
    "\n",
    "### Enter: Word Embeddings\n",
    "**Key idea:** Represent each word as a dense vector where similar words have similar vectors.\n",
    "\n",
    "- Words are mapped to continuous vectors (e.g., 100 dimensions instead of 3000)\n",
    "- The network learns these representations during training\n",
    "- Semantically similar words end up close together in vector space\n",
    "\n",
    "We'll use PyTorch's [Embedding layer](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) which learns a dense vector for each word in our vocabulary.\n",
    "\n",
    "![Embedding architecture](https://pytorch.org/tutorials/_images/text_sentiment_ngrams_model.png)\n",
    "*Architecture with embedding layer (from pytorch.org)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data: Convert Text to Token IDs\n",
    "\n",
    "First, we need to convert words to numerical IDs that the embedding layer can process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r5uYW1OmUpfJ"
   },
   "outputs": [],
   "source": [
    "# Get the analyzer from CountVectorizer (handles tokenization, preprocessing, stopword removal)\n",
    "an = word_to_ix.build_analyzer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Syg7NPVxUsWZ",
    "outputId": "ce371a2f-fa78-4c6e-ba9b-a1837341f898"
   },
   "outputs": [],
   "source": [
    "# Example: tokenize and process a sentence\n",
    "an(\"What made labubu go viral?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our vocabulary maps tokens to IDs\n",
    "print(f\"Vocabulary size: {len(word_to_ix.vocabulary_)}\")\n",
    "print(f\"Example mapping: 'hello' -> {word_to_ix.vocabulary_.get('hello', 'not in vocab')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dbU3fq40UxyR"
   },
   "outputs": [],
   "source": [
    "def create_input(dataset, analyzer, vocabulary):\n",
    "    \"\"\"\n",
    "    Convert text to sequences of token IDs.\n",
    "    \n",
    "    Args:\n",
    "        dataset: List of text samples\n",
    "        analyzer: Tokenizer function from CountVectorizer\n",
    "        vocabulary: Word-to-ID mapping\n",
    "    \n",
    "    Returns:\n",
    "        List of tensors, each containing token IDs for one sample\n",
    "    \n",
    "    Special tokens:\n",
    "        - IDs 0-2999: Vocabulary words\n",
    "        - ID 3000:  (unknown words not in vocabulary)\n",
    "        - ID 3001:  (padding, added later)\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_as_indices = []\n",
    "\n",
    "    for tweet in dataset:\n",
    "        tokens = analyzer(tweet)\n",
    "        token_ids = []\n",
    "\n",
    "        for token in tokens:\n",
    "            if token in vocabulary:\n",
    "                token_ids.append(vocabulary[token]) # Known word\n",
    "            else:\n",
    "                token_ids.append(3000) # Unknown token\n",
    "\n",
    "        # If all tokens were removed (stopwords, etc.), add unknown token\n",
    "        if not token_ids:\n",
    "            token_ids.append(3000)\n",
    "        dataset_as_indices.append(torch.LongTensor(token_ids).to(device))\n",
    "\n",
    "    return dataset_as_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the dataset as ids of tokens\n",
    "dataset_as_ids = create_input(tr_data.tweet, an, word_to_ix.vocabulary_)\n",
    "dataset_as_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: view token IDs for a sample\n",
    "print(f\"Sample tweet: '{tr_data.iloc[90]['tweet']}'\")\n",
    "print(f\"Token IDs: {dataset_as_ids[90]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Padding Sequences\n",
    "\n",
    "**Problem:** Neural networks expect fixed-size inputs, but tweets have different lengths.\n",
    "\n",
    "**Solution:** Pad shorter sequences with a special `<PAD>` token (ID 3001) to make all sequences the same length.\n",
    "\n",
    "![Padding visualization](https://miro.medium.com/max/1218/1*zsIXWoN0_CE9PXzmY3tIjQ.png)\n",
    "*Padding sequences to uniform length (image from towardsdatascience.com)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4qxWFBdj3d_n",
    "outputId": "b2ce0d82-e7ad-44ff-bfa7-03e67cb28bbe"
   },
   "outputs": [],
   "source": [
    "tr_data.tweet.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by length (groups similar-length sequences together for efficiency)\n",
    "tr_data = tr_data.assign(length=tr_data.tweet.str.len()).sort_values(by='length')\n",
    "val_data = val_data.assign(length=val_data.tweet.str.len()).sort_values(by='length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Example: pad a list of sequences\n",
    "sample_sequences = [\n",
    "    torch.tensor([1, 2, 3]),\n",
    "    torch.tensor([4, 5]),\n",
    "    torch.tensor([6, 7, 8, 9])\n",
    "]\n",
    "padded = pad_sequence(sample_sequences, batch_first=True, padding_value=3001)\n",
    "print(f\"Original sequences:\\n{sample_sequences}\")\n",
    "print(f\"\\nPadded sequences (batch_first=True):\\n{padded}\")\n",
    "print(f\"Shape: {padded.shape}  # [num_sequences, max_length]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4cYXPNg3d_o"
   },
   "source": [
    "`torch.nn.utils.rnn.pad_sequence` takes a list of tensors as input (sequences), calculates max length, and then pads all the sequences with `padding_value` to make them all have the same length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Me6QHFBV3d_p"
   },
   "source": [
    "Here you can see the dimension of `padded`, so max length among the sequences is 86."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCPFCrMbXIAs"
   },
   "outputs": [],
   "source": [
    "def prepare_dataloader_with_padding(tr_data, val_data, word_to_ix):\n",
    "    \"\"\"\n",
    "    Convert text to padded token ID sequences and create data loaders.\n",
    "    \n",
    "    Returns tuples of (padded_sequences, labels, original_lengths, raw_texts)\n",
    "    \"\"\"\n",
    "    \n",
    "    tr_data_vecs = pad_sequence(\n",
    "        create_input(tr_data.tweet, an, word_to_ix.vocabulary_),\n",
    "        batch_first=True, # Shape: [batch_size, max_length]\n",
    "        padding_value=3001,\n",
    "    )\n",
    "    tr_labels = torch.LongTensor(tr_data.label.tolist()).to(device)\n",
    "    tr_lens = torch.LongTensor(\n",
    "        [len(i) for i in create_input(tr_data.tweet, an, word_to_ix.vocabulary_)] #len of tweets\n",
    "    )\n",
    "    # Print information about sequence lengths (stored BEFORE padding for pack_padded_sequence)\n",
    "    print(f\"\\nTraining sequences: {tr_data_vecs.shape[0]} samples padded to max length {tr_data_vecs.shape[1]}\")\n",
    "    print(f\"Original lengths (before padding): min={tr_lens.min()}, max={tr_lens.max()}, mean={tr_lens.float().mean():.1f}\")\n",
    "    #print(f\"Lengths tensor shape: {tr_lens.shape}\")\n",
    "\n",
    "    # We also add the texts to the batches\n",
    "    # This is for the Transformer models, you won't need this in the next experiments\n",
    "    tr_raw_texts = tr_data.tweet.tolist()\n",
    "\n",
    "    val_data_vecs = pad_sequence(\n",
    "        create_input(val_data.tweet, an, word_to_ix.vocabulary_),\n",
    "        batch_first=True,\n",
    "        padding_value=3001,\n",
    "    )\n",
    "    val_labels = torch.LongTensor(val_data.label.tolist()).to(device)\n",
    "    val_lens = torch.LongTensor(\n",
    "        [len(i) for i in create_input(val_data.tweet, an, word_to_ix.vocabulary_)]\n",
    "    )\n",
    "\n",
    "    val_raw_texts = val_data.tweet.tolist()\n",
    "\n",
    "    # Create data loaders with 4 elements per sample\n",
    "    tr_data_loader = [\n",
    "        (sample, label, length, sent)\n",
    "        for sample, label, length, sent in zip(\n",
    "            tr_data_vecs, tr_labels, tr_lens, tr_raw_texts\n",
    "        )\n",
    "    ]\n",
    "    val_data_loader = [\n",
    "        (sample, label, length, sent)\n",
    "        for sample, label, length, sent in zip(\n",
    "            val_data_vecs, val_labels, val_lens, val_raw_texts\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return tr_data_loader, val_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EZvbpqCwXY3E",
    "outputId": "c097e26f-f49f-4269-8efc-cfb707d4cd22"
   },
   "outputs": [],
   "source": [
    "# Prepare padded data\n",
    "tr_data_loader, val_data_loader = prepare_dataloader_with_padding(\n",
    "    tr_data, val_data, word_to_ix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBSJgL9rXgDG"
   },
   "outputs": [],
   "source": [
    "def create_dataloader_iterators_with_padding(\n",
    "    tr_data_loader, val_data_loader, BATCH_SIZE\n",
    "):\n",
    "    train_iterator = DataLoader(\n",
    "        tr_data_loader,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    valid_iterator = DataLoader(\n",
    "        val_data_loader,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return train_iterator, valid_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_XLM8WHqZCim"
   },
   "outputs": [],
   "source": [
    "# Create DataLoader iterators\n",
    "train_iterator, valid_iterator = create_dataloader_iterators_with_padding(\n",
    "    tr_data_loader, val_data_loader, BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspect a batch:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sLbPdOtA3d_q",
    "outputId": "77069a65-801a-4fc0-fdc3-7bdb7561571c"
   },
   "outputs": [],
   "source": [
    "padded_samples, labels, orig_lengths, raw_texts = next(iter(train_iterator))\n",
    "print(f'Dimension of tensors with data samples (BATCH_SIZE, max_sequence_length): {padded_samples.shape}')\n",
    "print(f'Number of tweets in batch: {len(raw_texts)}')\n",
    "print(f'\\nExample (2nd sample in batch):')\n",
    "print(f'  Token IDs (padded): {padded_samples[1]}')\n",
    "print(f'  Original length: {orig_lengths[1]} tokens')\n",
    "print(f\"  Label: {labels[1].item()} ({'OFF' if labels[1].item() == 1 else 'NOT'})\")\n",
    "print(f'  Raw text: \"{raw_texts[1]}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Building the Embedding-Based Model\n",
    "\n",
    "### Architecture\n",
    "\n",
    "![Embedding + Pooling architecture](https://github.com/bentrevett/pytorch-sentiment-analysis/raw/b4efbefa47672174394a8b6a27d4e7bc193bc224/assets/sentiment8.png)\n",
    "\n",
    "*Bag-of-Words model with embedding layer and max pooling (from bentrevett)*\n",
    "\n",
    "**How it works:**\n",
    "1. **Embedding layer:** Maps each token ID to a dense vector\n",
    "2. **Max pooling:** Reduces the sequence of word embeddings to a single vector by taking the maximum value across each dimension\n",
    "3. **Linear layer:** Maps the pooled vector to class scores\n",
    "\n",
    "**Max pooling example:**\n",
    "```\n",
    "Word embeddings:\n",
    "  \"I\"    → [0.1, 0.3, 0.2]\n",
    "  \"hate\" → [0.5, 0.7, 0.6]\n",
    "  \"this\" → [0.2, 0.1, 0.3]\n",
    "  \"film\" → [0.4, 0.9, 0.8]\n",
    "\n",
    "Max pooling (take max of each column):\n",
    "  Result → [0.5, 0.9, 0.8]  ← This represents the entire tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k85Rbx-3ZLq9"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BoWClassifierWithEmbedding(nn.Module):\n",
    "    \"\"\"Bag-of-Words classifier using learned embeddings and max pooling.\"\"\"\n",
    "    def __init__(self, num_labels, vocab_size, embedding_dim):\n",
    "        super(BoWClassifierWithEmbedding, self).__init__()\n",
    "\n",
    "        # Embedding layer: maps token IDs to dense vectors\n",
    "        # vocab_size: total number of words (including  and )\n",
    "        # embedding_dim: size of each word vector\n",
    "        # padding_idx: ID for padding token (always maps to zeros, not trained)\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=3001)\n",
    "        # Enable training of embeddings (can be set to False to use pre-trained embeddings)\n",
    "        self.embedding.weight.requires_grad = True\n",
    "        # Linear layer: maps pooled embedding to class scores\n",
    "        self.linear = nn.Linear(embedding_dim, num_labels)\n",
    "\n",
    "    def forward(self, text, sequence_lens):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \n",
    "        Args:\n",
    "            text: Token IDs [batch_size, seq_len]\n",
    "            sequence_lens: Original sequence lengths (not used here)\n",
    "        \n",
    "        Returns:\n",
    "            Log probabilities [batch_size, num_labels]\n",
    "        \"\"\"\n",
    "        # Convert token IDs to embeddings\n",
    "        # Shape: [batch_size, seq_len] → [batch_size, seq_len, embedding_dim]\n",
    "        embedded = self.embedding(text)  \n",
    "        # Max pooling: reduce sequence to single vector\n",
    "        # For each of the embedding_dim dimensions, take the max value across all words\n",
    "        # kernel_size=(seq_len, 1) means: max over all words, separately for each embedding dimension\n",
    "        # Shape: [batch_size, seq_len, embedding_dim] → [batch_size, embedding_dim]\n",
    "        pooled = nn.functional.max_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1)  # dim=64x100 (batch_size x embedding_dim)\n",
    "        # Pass through linear layer and apply log_softmax\n",
    "        return nn.functional.log_softmax(self.linear(pooled), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IwBofSXr3d_q"
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "INPUT_DIM = VOCAB_SIZE + 2  # 3002\n",
    "OUTPUT_DIM = 2\n",
    "EMBEDDING_DIM = 100  # Each word represented as a 100-dimensional vector\n",
    "HIDDEN_DIM = 20\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "model = BoWClassifierWithEmbedding(OUTPUT_DIM, INPUT_DIM, EMBEDDING_DIM)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9H7nwaH3d_q"
   },
   "outputs": [],
   "source": [
    "# Set up training\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.NLLLoss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "print(model)\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Embedding parameters: {model.embedding.weight.numel()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "taiga3wN3d_q",
    "outputId": "c6c3bd65-9dc3-4fda-f795-709653bfc642"
   },
   "outputs": [],
   "source": [
    "### Train the Model\n",
    "training_loop(epoch_number=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** The embedding layer adds many parameters (vocab_size × embedding_dim = 3002 × 100 = 300,200). This gives the model more capacity to learn, but also increases the risk of overfitting on small datasets. Watch the validation loss carefully!\n",
    "\n",
    "***Optional: Using Pre-trained Embeddings***\n",
    "\n",
    "Instead of learning embeddings from scratch, you can load pre-trained embeddings like GloVe or Word2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KC-dHUk3d_q"
   },
   "source": [
    "## 12. Standard RNNs & LSTMs\n",
    "\n",
    "### Why Sequential Models?\n",
    "\n",
    "So far, our models have ignored word order:\n",
    "- **Bag-of-Words:** Treats \"I love this movie\" and \"This movie I love\" identically\n",
    "- **Max pooling:** Takes the maximum embedding value, losing sequence information\n",
    "\n",
    "**RNNs process text sequentially**, maintaining a hidden state that captures information from previous words. This allows them to understand context and word order.\n",
    "\n",
    "### Understanding RNNs\n",
    "\n",
    "An RNN processes one word at a time, updating its hidden state at each step:\n",
    "\n",
    "![Unrolled RNN](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)\n",
    "*Unrolled RNN showing sequential processing (from [colah's blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/))*\n",
    "\n",
    "**Standard RNN module:**\n",
    "\n",
    "![RNN module](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png)\n",
    "*A single RNN cell applies a simple transformation (from [colah's blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/))*\n",
    "\n",
    "**Problem with standard RNNs:** They struggle to learn long-term dependencies due to vanishing/exploding gradients.\n",
    "\n",
    "### Long Short-Term Memory (LSTM)\n",
    "\n",
    "LSTMs solve the long-term dependency problem using a more sophisticated cell structure with gates that control information flow:\n",
    "\n",
    "![LSTM module](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png)\n",
    "*LSTM cell with gates for controlling information (from [colah's blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/))*\n",
    "\n",
    "**LSTM outputs:**\n",
    "\n",
    "![LSTM outputs](https://i.stack.imgur.com/SjnTl.png)\n",
    "\n",
    "*LSTM produces hidden states (h) and cell states (c) at each time step (from stackoverflow)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGOrrC2U3d_q"
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Text classifier using LSTM for sequential processing.\n",
    "    \n",
    "    Architecture: Embeddings → LSTM → Linear → Output\n",
    "    The LSTM processes the sequence and we use its final hidden state for classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_labels, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        # Embedding layer (same as before)\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=3001)\n",
    "        self.embedding.weight.requires_grad = True\n",
    "\n",
    "        # LSTM layer\n",
    "        # Takes sequence of embeddings, outputs sequence of hidden states\n",
    "        # Documentation: https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,          # Size of input embeddings\n",
    "            hidden_dim,             # Size of hidden state\n",
    "            batch_first=True,       # Input shape: [batch, seq_len, features]\n",
    "            num_layers=1,           # Single LSTM layer\n",
    "            bidirectional=False,    # Process sequence left-to-right only\n",
    "        )\n",
    "        # Classification layer (uses final LSTM hidden state)\n",
    "        self.linear = nn.Linear(hidden_dim, num_labels)\n",
    "        # Dropout for regularization to overcome overfitting\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, text, sequence_lens):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \n",
    "        Args:\n",
    "            text: Padded token IDs [batch_size, max_seq_len]\n",
    "            sequence_lens: Original sequence lengths (before padding)\n",
    "        \n",
    "        Returns:\n",
    "            Log probabilities [batch_size, num_labels]\n",
    "        \"\"\"\n",
    "        # Convert token IDs to embeddings\n",
    "        # Shape: [batch_size, seq_len, embedding_dim]\n",
    "        embedded = self.embedding(text)\n",
    "\n",
    "        # Pack padded sequences to avoid computing LSTM on padding tokens\n",
    "        # This is more efficient and prevents the LSTM from learning patterns in padding\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded,\n",
    "            sequence_lens,\n",
    "            enforce_sorted=False,   # Don't require sequences sorted by length\n",
    "            batch_first=True\n",
    "        )\n",
    "        # Pass through LSTM\n",
    "        # packed_outputs: all hidden states (one per time step)\n",
    "        # h: final hidden state [num_layers, batch_size, hidden_dim]\n",
    "        # c: final cell state (not used for classification)\n",
    "        packed_outputs, (h, c) = self.lstm(packed)\n",
    "        # Unpack the outputs (converts back to padded format)\n",
    "        # We don't actually use lstm_outputs here, but this shows how to extract them\n",
    "        lstm_outputs, lens = nn.utils.rnn.pad_packed_sequence(\n",
    "            packed_outputs, batch_first=True\n",
    "        )\n",
    "\n",
    "        # Use the final hidden state for classification\n",
    "        # h[-1] selects the last layer's hidden state\n",
    "        # Shape: [batch_size, hidden_dim]\n",
    "        final_hidden = h[-1]\n",
    "        \n",
    "        # Apply dropout and linear transformation\n",
    "        output = self.linear(self.dropout(final_hidden))\n",
    "        \n",
    "        # Convert to log probabilities\n",
    "        return nn.functional.log_softmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QgKkr4bZSPG"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = VOCAB_SIZE + 2  # 3000 +  + \n",
    "OUTPUT_DIM = 2\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 20  # Size of LSTM hidden state\n",
    "\n",
    "# Initialize model\n",
    "model = LSTMClassifier(OUTPUT_DIM, INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVrF6CgmZUeg"
   },
   "outputs": [],
   "source": [
    "# Set up training\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.NLLLoss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "print(model)\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bHCHriijZU9F",
    "outputId": "7709e9e3-9426-4f11-b620-2b5ff8c06c97"
   },
   "outputs": [],
   "source": [
    "training_loop(epoch_number=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding pack_padded_sequence\n",
    "\n",
    "**Why pack sequences?**\n",
    "- Padded tokens (ID 3001) don't contain useful information\n",
    "- Without packing, the LSTM would waste computation on padding\n",
    "- Packing tells the LSTM where each sequence actually ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Reading: Advanced LSTMs\n",
    "\n",
    "Interested in the latest LSTM developments? Check out:\n",
    "\n",
    "**[xLSTM: Extended Long Short-Term Memory](https://arxiv.org/abs/2405.04517)** by Sepp Hochreiter's group (2024)\n",
    "\n",
    "Key innovations:\n",
    "- **Exponential gating:** Improved information flow control\n",
    "- **New memory structures:** Better handling of long-term dependencies\n",
    "- **mLSTM variant:** Addresses parallelization limitations of traditional LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCLmfXf03d_r"
   },
   "source": [
    "## 13. Transformers\n",
    "\n",
    "### Why Transformers? Problems with RNNs\n",
    "\n",
    "Recall that we used LSTMs to encode sequences into vectors. While effective, RNNs have fundamental limitations:\n",
    "\n",
    "**Problem 1: No Parallelism**\n",
    "- LSTMs process tokens sequentially (left-to-right), requiring previous steps to complete before processing the next token\n",
    "- Cannot parallelize computation across the sequence\n",
    "\n",
    "**Problem 2: Long-Range Dependencies**\n",
    "- Despite improvements over vanilla RNNs, LSTMs still struggle with very long-range dependencies\n",
    "- Example: \"The people who called and wanted to rent your house when you go away next year are from California\"\n",
    "- Too many backpropagation steps between distant related words\n",
    "\n",
    "![Encoder-Decoder RNN](https://miro.medium.com/v2/resize:fit:720/format:webp/1*1JcHGUU7rFgtXC_mydUA_Q.jpeg)\n",
    "*Traditional seq2seq without attention (from [medium](https://towardsdatascience.com/understanding-encoder-decoder-sequence-to-sequence-model-679e04af4346))*\n",
    "\n",
    "### The Solution: Attention Mechanism\n",
    "\n",
    "The attention mechanism, introduced in 2014 ([Bahdanau et al.](https://arxiv.org/abs/1409.0473)), revolutionized NLP by allowing models to focus on relevant parts of the input when making predictions.\n",
    "\n",
    "![Encoder-Decoder with Attention](https://miro.medium.com/v2/resize:fit:640/format:webp/1*KrCUK30Y1R7TV7xE-ltcpg.png)\n",
    "*Seq2seq with attention mechanism (from [medium](https://medium.com/data-science-community-srm/understanding-encoders-decoders-with-attention-based-mechanism-c1eb7164c581))*\n",
    "\n",
    "**Key innovation:** Instead of compressing the entire input into a single vector, attention allows the model to look back at all input tokens when making predictions.\n",
    "\n",
    "### Transformers: \"Attention Is All You Need\"\n",
    "\n",
    "The [Transformer architecture](https://arxiv.org/abs/1706.03762) (Vaswani et al., 2017) eliminates recurrence entirely, relying solely on attention mechanisms.\n",
    "\n",
    "![Transformer Architecture](https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png)\n",
    "*Transformer architecture (from [machinelearningmastery.com](https://machinelearningmastery.com))*\n",
    "**Key features:**\n",
    "- **Self-attention:** Each word attends to all other words in the sequence\n",
    "- **Parallel processing:** No sequential dependencies, can process entire sequence at once\n",
    "- **Multi-headed attention:** Multiple attention mechanisms running in parallel\n",
    "\n",
    "**Self-attention example:**\n",
    "\"The animal didn't cross the street because **it** was too tired\"\n",
    "- Self-attention learns to associate \"it\" with \"animal\"\n",
    "\n",
    "![Self-attention mechanism](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*maneqIvralwRZWf0g3hS5w.png)\n",
    "*Self-attention visualization (from [towardsdatascience](https://towardsdatascience.com/all-you-need-to-know-about-attention-and-transformers-in-depth-understanding-part-1-552f0b41d021))*\n",
    "\n",
    "**Learn more:** [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) by Jay Alammar\n",
    "\n",
    "### BERT: Bidirectional Encoder Representations from Transformers\n",
    "\n",
    "[BERT](https://www.aclweb.org/anthology/N19-1423/) (Devlin et al., 2018) is a pre-trained transformer model that revolutionized NLP by enabling transfer learning.\n",
    "\n",
    "**Pre-training objectives:**\n",
    "1. **Masked Language Model (MLM):** Predict randomly masked words\n",
    "   - 15% of tokens are masked: 80% replaced with [MASK], 10% random token, 10% unchanged\n",
    "2. **Next Sentence Prediction (NSP):** Predict if two sentences are consecutive\n",
    "\n",
    "**Training scale:**\n",
    "- BERT-base: 110M parameters, trained on BookCorpus + English Wikipedia\n",
    "- Vocabulary size: 30,522 WordPiece tokens\n",
    "\n",
    "**Fine-tuning approach:**\n",
    "1. Load pre-trained BERT model\n",
    "2. Add task-specific classification layer on top\n",
    "3. Fine-tune on your labeled dataset (much smaller than pre-training data)\n",
    "4. Option: Freeze BERT weights and train only classification layer\n",
    "\n",
    "![BERT fine-tuning](https://production-media.paperswithcode.com/methods/new_BERT_Overall.jpg)\n",
    "*BERT fine-tuning for different tasks*\n",
    "\n",
    "### WordPiece Tokenization\n",
    "\n",
    "BERT uses its own tokenizer - **always tokenize with BERT's tokenizer, not your custom preprocessing!**\n",
    "\n",
    "**Special tokens:**\n",
    "- `[CLS]`: Classification token (start of sequence)\n",
    "- `[SEP]`: Separator token (end of sequence)\n",
    "- `[MASK]`: Masked token (for pre-training)\n",
    "- `[UNK]`: Unknown token\n",
    "- `[PAD]`: Padding token (ID 0)\n",
    "\n",
    "**How it works:** Subword tokenization between character and word level\n",
    "- Frequent words: kept whole\n",
    "- Rare words: split into subwords\n",
    "- Unknown characters: handled gracefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Example tokenization\n",
    "text = \"I love Python 🐍 and data analysis 📊!\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(f\"Tokens: {tokens}\")\n",
    "\n",
    "# Check vocabulary size\n",
    "print(f\"Vocabulary size: {len(tokenizer.get_vocab())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: complex name tokenization\n",
    "tokens = tokenizer.tokenize(\"His full name is Fyodor Mikhailovich Dostoevsky\")\n",
    "print(f\"Name tokens: {tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenize two sentences:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format: [CLS] Sentence 1 [SEP] Sentence 2 [SEP]\n",
    "encoded = tokenizer(\"There are black cats and black dogs.\", \"Another sentence.\")\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> [CLS] Sentence 1 [SEP] Sentence 2 [SEP]\n",
    "\n",
    "100: [UNK] (Unknown token)\n",
    "\n",
    "101: [CLS] (Classification Token)\n",
    "\n",
    "102: [SEP] (Separator Token): The [CLS] token is special in BERT as it is used to aggregate information from the entire sequence. Its output embedding (from the last layer of the model) is often used for classification tasks (e.g., sentiment analysis, sentence-pair classification).\n",
    "\n",
    "103: [MASK] (Masked Token)\n",
    "\n",
    "0: [PAD] (Padding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tokenizer))\n",
    "print(len(tokenizer.get_vocab()))\n",
    "\n",
    "tokenizer.tokenize(\"His full name is Fyodor Mikhailovich Dostoevsky\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, let's have a look at how another tokeniser works:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# BERTweet (trained on tweets)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\n",
    "text = \"I love Python 🐍 and data analysis 📊!\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning BERT on Our Dataset with HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7PL6IcRoQeB"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Convert dataframes to lists\n",
    "train_texts = tr_data.tweet.tolist()\n",
    "train_labels = tr_data.label.tolist()\n",
    "val_texts = val_data.tweet.tolist()\n",
    "val_labels = val_data.label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zi0o8GfTo0do"
   },
   "outputs": [],
   "source": [
    "# Tokenize all at once\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create PyTorch Dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsBVoBCjpF9s"
   },
   "outputs": [],
   "source": [
    "class TweetDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Custom dataset for BERT fine-tuning.\"\"\"\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = TweetDataset(train_encodings, train_labels)\n",
    "val_dataset = TweetDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define metrics:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BskU_jlPpUrd"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    \"\"\"Compute metrics for evaluation.\"\"\"\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average='binary', pos_label=1\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train with Weights & Biases tracking:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize W&B\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "wandb.init(project=\"bert-finetuning\", name=f\"bert-base-uncased-semeval-{current_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./results_bert_{current_date}\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=5e-5,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=f\"./logs_bert_{current_date}\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_loss',\n",
    "    greater_is_better=False,\n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "# Final evaluation\n",
    "results = trainer.evaluate()\n",
    "print(f\"\\nFinal results: {results}\")\n",
    "wandb.log(results)\n",
    "\n",
    "# Save model\n",
    "trainer.save_model(f\"./saved_model_bert_{current_date}\")\n",
    "\n",
    "# Finish W&B run\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Create Assignment",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "nlp_ie_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0084f75d88624fc38d3f5ad29c6718a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "044657a7e9f04389bd52da3688e659db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06ae4a2c9bff449a96469ca79c4f6f6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5797a82c4e3844c8be1fe9b75e97e54c",
      "placeholder": "​",
      "style": "IPY_MODEL_b0f6dedbc1794b1ab53a0e8f7c7f0151",
      "value": "Downloading artifacts: 100%"
     }
    },
    "0d2d068d26a149bb8dc313869d383b18": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e15f6fd75974415989ce53e7e05904a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "117939875677424c9654ba2659fc2afd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef7df33e327b4f1b82b9f9ed5aa956d6",
      "max": 542529064,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_52eb4b4f37794bbcb7be0affffe0434b",
      "value": 542529064
     }
    },
    "12b7833abd174d00a552ce1ffcc12cba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6af4d8fe63d4cb987fbf3dcb818f232",
      "placeholder": "​",
      "style": "IPY_MODEL_708621a183564cc492e3e31221f09ea3",
      "value": " 7/7 [00:05&lt;00:00,  1.24it/s]"
     }
    },
    "146565c18d7940358a93ac1f139e2bd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "15798adc99b84a64bee5e2bf516d3479": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0084f75d88624fc38d3f5ad29c6718a2",
      "max": 1078931,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8c2dd19ab40e40cdab1e0264bb3733b4",
      "value": 1078931
     }
    },
    "1cab0d74c9a9497296c05768cf00f236": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb6eb80a86d94015b765c39913a3da4a",
      "placeholder": "​",
      "style": "IPY_MODEL_e4fafd7a57704de18116e8f917f6b0b9",
      "value": " 2.91M/2.91M [00:00&lt;00:00, 8.82MB/s]"
     }
    },
    "2053c0e273a14a5ca7181ef1d715da9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49b86b4023f447a38f4cd386348945da",
      "placeholder": "​",
      "style": "IPY_MODEL_f869070b970744e8805c44e8ec57eedb",
      "value": "Downloading (…)solve/main/bpe.codes: 100%"
     }
    },
    "21e12a93ca1040ee9c796a1bd1ddb690": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "27f0c4c773e841d0ad3fd5ca4578387f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2863cf99a4c94403970773aae953a77b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c04580fc55844878dfb819129cc4159",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df04aae002a8427dbbf095fa4e83a3ee",
      "value": 7
     }
    },
    "2bc8e3b3cc9447c5baeb3e291ca59950": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c04580fc55844878dfb819129cc4159": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2da8cfea31114cddb4bccf2a7a070442": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6de9018faa54c3191df2700d2bb2f2b",
      "max": 843438,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f326ca5639e949e9bec56868fc153679",
      "value": 843438
     }
    },
    "3173c3d5743a48d89df922c77991e941": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a560cc0902d44a60a7e2eebf951249e5",
      "placeholder": "​",
      "style": "IPY_MODEL_c9f9c38161214356b21d3a10fb04e655",
      "value": " 1.08M/1.08M [00:00&lt;00:00, 5.44MB/s]"
     }
    },
    "3459a07ff77442a0a99d62a564aeab5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7c1fa3d8b54f4499a16b37b941b856d3",
       "IPY_MODEL_4cd5bef030644364ad11b5fee58e1279",
       "IPY_MODEL_44de39b785d14456997e3cafd6aa7578"
      ],
      "layout": "IPY_MODEL_e74e23913379453aa16931b744e2e2d8"
     }
    },
    "38b0cb2f897d4150846c1701250d7d81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "39240fd76ca140eeae24ca4648a835ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_044657a7e9f04389bd52da3688e659db",
      "placeholder": "​",
      "style": "IPY_MODEL_5406f6dd96cc4e76aa3ff3bdc957a21c",
      "value": " 7/7 [00:08&lt;00:00,  1.49s/it]"
     }
    },
    "3a14450014e74d918381af193a4aade0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a8c5d093fcd4ce7bc45af7cbb574d4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0cf938381f648bb80c3fba33aedcfed",
      "placeholder": "​",
      "style": "IPY_MODEL_3ff241b617a34ff2ae37e965c62c1692",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "3d72d47fb5554cebbba3a299aa42eadf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3ff241b617a34ff2ae37e965c62c1692": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40ed48da1f6b40bc923fe0b005618c9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "42b4e686cded4f98a8f75c028e008278": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43d5518c9522411180d5b935694a99ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c79ae4ad113a434c948e5137a79fcad8",
      "placeholder": "​",
      "style": "IPY_MODEL_c82059cc49564e9991483f1e0d5a6b1b",
      "value": "Downloading artifacts: 100%"
     }
    },
    "44de39b785d14456997e3cafd6aa7578": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e25007b6c2e49e8ae6f61c5b927c6c1",
      "placeholder": "​",
      "style": "IPY_MODEL_59d7aa0205b1432f8e0e069df1de55bb",
      "value": " 558/558 [00:00&lt;00:00, 36.7kB/s]"
     }
    },
    "45ea52ab0e3341f7820c404ef4538591": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "463212231f8848cca4e4a4e90d18c61a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_583969762b8348f49e085414635695d6",
      "placeholder": "​",
      "style": "IPY_MODEL_f51c7658838541089f4719fc6ec54c2e",
      "value": " 7/7 [00:05&lt;00:00,  1.25it/s]"
     }
    },
    "4765f41c37a143ba955a1fb03434b6cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27f0c4c773e841d0ad3fd5ca4578387f",
      "placeholder": "​",
      "style": "IPY_MODEL_994b59e22e78433ca5abd14157557e2c",
      "value": "Downloading artifacts: 100%"
     }
    },
    "49b86b4023f447a38f4cd386348945da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b8bd74d2b824ebb95d927efeda3b380": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74d80fa96e1547c1bd4e0991fd02d2a7",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a58e61a346bc47f7bc4125de08fe9f90",
      "value": 7
     }
    },
    "4cd5bef030644364ad11b5fee58e1279": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5ca0736f19b43f48d995c66fe3a790b",
      "max": 558,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_146565c18d7940358a93ac1f139e2bd0",
      "value": 558
     }
    },
    "4d85c970d7d64ed2bddfe8ae25bdff5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "51d17cbe78904d81883dfb1a6c376736": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dabe388568ab4603a8507fca7d1ae509",
      "max": 2912687,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3d72d47fb5554cebbba3a299aa42eadf",
      "value": 2912687
     }
    },
    "52eb4b4f37794bbcb7be0affffe0434b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5406f6dd96cc4e76aa3ff3bdc957a21c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5797a82c4e3844c8be1fe9b75e97e54c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "583969762b8348f49e085414635695d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59d7aa0205b1432f8e0e069df1de55bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bcdef7aa0eb4ea384334d03f00415e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c29713b593a4086948e4fe12824bb62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c50ced65df84dbda3cf54a5cca0f837": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4c891e1590e498483757ed001c63f2a",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4d85c970d7d64ed2bddfe8ae25bdff5c",
      "value": 7
     }
    },
    "5dbfba30baad4c919daf14275963b93a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e25007b6c2e49e8ae6f61c5b927c6c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62b5648966e64af6a0b7098244e95898": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82f20a9a535340b281c1d5883ff22f78",
      "placeholder": "​",
      "style": "IPY_MODEL_b094b0688076455e89d671010561a823",
      "value": "Downloading artifacts: 100%"
     }
    },
    "648d768da4c74ca68fe1622269cdf08a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85a8c21fd9ed46459dd055cd54647cec",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_73cbc3d4f873410b95e5c10de91590c6",
      "value": 7
     }
    },
    "6ac1188056784b96b03c18af698a3555": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c0137e3e2bd04202819a245bd779a172",
       "IPY_MODEL_51d17cbe78904d81883dfb1a6c376736",
       "IPY_MODEL_1cab0d74c9a9497296c05768cf00f236"
      ],
      "layout": "IPY_MODEL_c5a99c03a661472a8528ac63006bd054"
     }
    },
    "708621a183564cc492e3e31221f09ea3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7100823ec0bb4137b918ef42b000a71f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_802e81c53b4b470bb496bfc457df3913",
      "placeholder": "​",
      "style": "IPY_MODEL_e4db997df90f459c9af94a29c99a5207",
      "value": " 843k/843k [00:00&lt;00:00, 4.13MB/s]"
     }
    },
    "73cbc3d4f873410b95e5c10de91590c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "74d80fa96e1547c1bd4e0991fd02d2a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c1fa3d8b54f4499a16b37b941b856d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a14450014e74d918381af193a4aade0",
      "placeholder": "​",
      "style": "IPY_MODEL_21e12a93ca1040ee9c796a1bd1ddb690",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "7f1430bfe5e34137a8f18babd624c7ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "802e81c53b4b470bb496bfc457df3913": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82f20a9a535340b281c1d5883ff22f78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85a8c21fd9ed46459dd055cd54647cec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ab0b04ab3614908b7d6b116e6c4e1eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c2dd19ab40e40cdab1e0264bb3733b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8ea0dfe133984d8a82026d93d1aa2f7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f9432d8165854debaa7d0f33acf2f471",
       "IPY_MODEL_2da8cfea31114cddb4bccf2a7a070442",
       "IPY_MODEL_7100823ec0bb4137b918ef42b000a71f"
      ],
      "layout": "IPY_MODEL_42b4e686cded4f98a8f75c028e008278"
     }
    },
    "984ed9f1ef754c938a900f48d11279a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98ce9422525e40f0be280ed8579432dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f1430bfe5e34137a8f18babd624c7ee",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_38b0cb2f897d4150846c1701250d7d81",
      "value": 7
     }
    },
    "994b59e22e78433ca5abd14157557e2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a66c855f00449c08111d8f52eecef1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eb3008aa2bec4526a88ccee75b493b30",
       "IPY_MODEL_5c50ced65df84dbda3cf54a5cca0f837",
       "IPY_MODEL_39240fd76ca140eeae24ca4648a835ef"
      ],
      "layout": "IPY_MODEL_dd8f1c9851bd45c1b46bc2c932307c2e"
     }
    },
    "9cb3c33c775646ad969bf63742aac67c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3a8c5d093fcd4ce7bc45af7cbb574d4d",
       "IPY_MODEL_117939875677424c9654ba2659fc2afd",
       "IPY_MODEL_eaad47593aa74e78afd8bd4f59d275b8"
      ],
      "layout": "IPY_MODEL_0d2d068d26a149bb8dc313869d383b18"
     }
    },
    "9e0ad7e6300044d59b637cb1c913718f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_62b5648966e64af6a0b7098244e95898",
       "IPY_MODEL_2863cf99a4c94403970773aae953a77b",
       "IPY_MODEL_a242cf037c6e446f9f33fc01f25fa97e"
      ],
      "layout": "IPY_MODEL_be8397673e9b4fecbb404fe0b898a61c"
     }
    },
    "9f2d1f3c0e064c06b1e1d823b1200396": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a242cf037c6e446f9f33fc01f25fa97e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f2d1f3c0e064c06b1e1d823b1200396",
      "placeholder": "​",
      "style": "IPY_MODEL_40ed48da1f6b40bc923fe0b005618c9d",
      "value": " 7/7 [00:05&lt;00:00,  1.20it/s]"
     }
    },
    "a560cc0902d44a60a7e2eebf951249e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a58e61a346bc47f7bc4125de08fe9f90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a690261e4b3f427d8a09ff92d8469714": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_06ae4a2c9bff449a96469ca79c4f6f6f",
       "IPY_MODEL_648d768da4c74ca68fe1622269cdf08a",
       "IPY_MODEL_b9876923900640b39c449dc83328e88c"
      ],
      "layout": "IPY_MODEL_c3f74e8f21c84c4380a8c978ab608b22"
     }
    },
    "b094b0688076455e89d671010561a823": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0f6dedbc1794b1ab53a0e8f7c7f0151": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4c891e1590e498483757ed001c63f2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7f63463a8de4bc5a52d6a03a57abcfa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9876923900640b39c449dc83328e88c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bcdef7aa0eb4ea384334d03f00415e6",
      "placeholder": "​",
      "style": "IPY_MODEL_f7eaf6f2238143d1a46cd2c083c97f95",
      "value": " 7/7 [00:06&lt;00:00,  1.07it/s]"
     }
    },
    "bb6eb80a86d94015b765c39913a3da4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be8397673e9b4fecbb404fe0b898a61c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bedd05a3dcbb4a90bbaaff13da1c0d55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4765f41c37a143ba955a1fb03434b6cd",
       "IPY_MODEL_4b8bd74d2b824ebb95d927efeda3b380",
       "IPY_MODEL_12b7833abd174d00a552ce1ffcc12cba"
      ],
      "layout": "IPY_MODEL_c6e84c2523b040b3ac7f37f376b56e5d"
     }
    },
    "c0137e3e2bd04202819a245bd779a172": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_984ed9f1ef754c938a900f48d11279a1",
      "placeholder": "​",
      "style": "IPY_MODEL_5c29713b593a4086948e4fe12824bb62",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "c0cf938381f648bb80c3fba33aedcfed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c265a33272d94721a2ad0d16f1576e5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3f74e8f21c84c4380a8c978ab608b22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5a99c03a661472a8528ac63006bd054": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5b63442c79f4f1098135ba291c75ac4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_43d5518c9522411180d5b935694a99ba",
       "IPY_MODEL_98ce9422525e40f0be280ed8579432dc",
       "IPY_MODEL_463212231f8848cca4e4a4e90d18c61a"
      ],
      "layout": "IPY_MODEL_0e15f6fd75974415989ce53e7e05904a"
     }
    },
    "c6de9018faa54c3191df2700d2bb2f2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6e84c2523b040b3ac7f37f376b56e5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c79ae4ad113a434c948e5137a79fcad8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7f998f7f4f74e189b76e771f6626f53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2053c0e273a14a5ca7181ef1d715da9b",
       "IPY_MODEL_15798adc99b84a64bee5e2bf516d3479",
       "IPY_MODEL_3173c3d5743a48d89df922c77991e941"
      ],
      "layout": "IPY_MODEL_b7f63463a8de4bc5a52d6a03a57abcfa"
     }
    },
    "c82059cc49564e9991483f1e0d5a6b1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9f9c38161214356b21d3a10fb04e655": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d5ca0736f19b43f48d995c66fe3a790b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dabe388568ab4603a8507fca7d1ae509": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db0c0de1b46e446084ee397a8acd80f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dd8f1c9851bd45c1b46bc2c932307c2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df04aae002a8427dbbf095fa4e83a3ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e4db997df90f459c9af94a29c99a5207": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4fafd7a57704de18116e8f917f6b0b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e6af4d8fe63d4cb987fbf3dcb818f232": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e74e23913379453aa16931b744e2e2d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eaad47593aa74e78afd8bd4f59d275b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c265a33272d94721a2ad0d16f1576e5a",
      "placeholder": "​",
      "style": "IPY_MODEL_8ab0b04ab3614908b7d6b116e6c4e1eb",
      "value": " 543M/543M [00:32&lt;00:00, 29.2MB/s]"
     }
    },
    "eb3008aa2bec4526a88ccee75b493b30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5dbfba30baad4c919daf14275963b93a",
      "placeholder": "​",
      "style": "IPY_MODEL_db0c0de1b46e446084ee397a8acd80f6",
      "value": "Downloading artifacts: 100%"
     }
    },
    "ef7df33e327b4f1b82b9f9ed5aa956d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f326ca5639e949e9bec56868fc153679": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f51c7658838541089f4719fc6ec54c2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7eaf6f2238143d1a46cd2c083c97f95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f869070b970744e8805c44e8ec57eedb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9432d8165854debaa7d0f33acf2f471": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45ea52ab0e3341f7820c404ef4538591",
      "placeholder": "​",
      "style": "IPY_MODEL_2bc8e3b3cc9447c5baeb3e291ca59950",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
